{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from matplotlib import pylab as plt\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from past.builtins import xrange\n",
    "from future.utils import iteritems\n",
    "import neupy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "import networkx as nx\n",
    "import gng\n",
    "from gng import GrowingNeuralGas\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gng = GrowingNeuralGas(data_sc)\n",
    "gng.fit_network(e_b=0.1, e_n=0.006, a_max=10, l=200, a=0.5, d=0.995, passes=8, plot_evolution=True)\n",
    "print('Found %d clusters.' % gng.number_of_clusters())\n",
    "gng.plot_clusters(gng.cluster_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gng import GrowingNeuralGas\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print('Generating data...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, marker = make_blobs(n_samples=500, n_features=2, centers=7, cluster_std=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns = ['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.y, df.x, c=marker, alpha = 1, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data = data.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebi = np.arange(0.05, 0.2, 0.03)\n",
    "eni = np.arange(0.005, 0.02, 0.003)\n",
    "amaxi = range(5,16,3)\n",
    "li = range(5,50,10)\n",
    "pasi = range(6,13,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df1 = pd.DataFrame([[1,2]], columns = ['Clusters', 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = clusters_df.append(clusters_df1 , ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.DataFrame(columns = ['Clusters', 'params', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in list(product(ebi,eni, amaxi, li,pasi)):\n",
    "    gng = []\n",
    "    print('Done.')\n",
    "    print('Fitting neural network...')\n",
    "    gng = GrowingNeuralGas(data, e_b = i[0], e_n= i[1] , a_max= i[2], l= i[3] , a=0.5, d=0.95, passes=i[4], plot_evolution=False)\n",
    "    gng.fit_network()\n",
    "    pdpd = gng.cluster_data()\n",
    "    \n",
    "    cluster_data = pd.DataFrame(pdpd, columns = ['values', 'clusters'])\n",
    "    results = pd.DataFrame(np.array([[cluster_data['values'].iloc[j][1] for j in range(0, len(cluster_data))],[cluster_data['clusters'].iloc[j] for j in range(0, len(cluster_data))]]), index = ['values', 'clusters']).transpose()\n",
    "    mid = pd.DataFrame({'clusters': results.clusters.value_counts().index.to_list(), 'count' : list(results.clusters.value_counts().values)})\n",
    "    std_ff = results.groupby(['clusters']).std()\n",
    "    new_std = std_ff.reset_index().fillna(0)\n",
    "    merge_results = mid.merge(new_std, on = ['clusters'], how = 'inner')\n",
    "    hmm = [merge_results['values'].iloc[j]*merge_results['count'].iloc[j]/merge_results['count'].sum() for j in range(0, len(merge_results))]\n",
    "    total_score = sum(hmm)\n",
    "    \n",
    "    clusters_df1 = pd.DataFrame([[gng.number_of_clusters(),[i[0], i[1] , i[2] , i[3], i[4]], total_score]], columns = ['Clusters', 'params', 'score'])\n",
    "    clusters_df = clusters_df.append(clusters_df1 , ignore_index = True)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df.to_excel('clusters_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_max - максимальное количество ребер вершины после поиска точек, следовательно больше возможных ребер - меньше кластеров\n",
    "# l - количество шагов от каждой точки по ребрам, больше шагов - меньше кластеров (грубо говоря)\n",
    "# a - параметр для уменьшения разброса возмоджных кластеров  по шагам, меньше a - больше кластеров\n",
    "# b - параметр для уменьшения длины наибольшего вектора по шагам, = 1 (ничего не происходит), при увеличении будет находить все больше кластеров (грубо говоря)\n",
    "# eps_b - шаг по текущей вершине в сторону ближайшей \n",
    "# eps_nei - шаг в поиске ближайших соседей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gng = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done.')\n",
    "print('Fitting neural network...')\n",
    "gng = GrowingNeuralGas(data, e_b = 0.05, e_n=0.01, a_max=10, l = 10, a=.5, d=.995, passes=10, plot_evolution=False)\n",
    "gng.fit_network()\n",
    "print('Found %d clusters.' % gng.number_of_clusters())\n",
    "gng.plot_clusters(gng.cluster_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found %d clusters.' % gng.number_of_clusters())\n",
    "gng.plot_clusters(gng.cluster_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = pd.DataFrame(gng.cluster_data(), columns = ['values', 'clusters'])\n",
    "results = pd.DataFrame(np.array([[cluster_data['values'].iloc[i][1] for i in range(0, len(cluster_data))],[cluster_data['clusters'].iloc[i] for i in range(0, len(cluster_data))]]), index = ['values', 'clusters']).transpose()\n",
    "mid = pd.DataFrame({'clusters': results.clusters.value_counts().index.to_list(), 'count' : list(results.clusters.value_counts().values)})\n",
    "std_ff = results.groupby(['clusters']).std()\n",
    "new_std = std_ff.reset_index().fillna(0)\n",
    "merge_results = mid.merge(new_std, on = ['clusters'], how = 'inner')\n",
    "hmm = [merge_results['values'].iloc[i]*merge_results['count'].iloc[i]/merge_results['count'].sum() for i in range(0, len(merge_results))]\n",
    "total_score = sum(hmm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rapid",
   "language": "python",
   "name": "rapid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
